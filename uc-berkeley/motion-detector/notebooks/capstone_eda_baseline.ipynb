{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6c3243",
   "metadata": {},
   "source": [
    "# Capstone Project — Initial Report & Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook satisfies the deliverables for **Module 20.1**:\n",
    "- Data cleaning + EDA\n",
    "- Clear, labeled visualizations\n",
    "- Feature engineering\n",
    "- **One baseline ML model** with metric + interpretation\n",
    "\n",
    "> **How to use:** Put your dataset into `../data/` and set `DATA_PATH` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d4839",
   "metadata": {},
   "source": [
    "## 2) Load data\n",
    "\n",
    "Update the `DATA_PATH` and (optionally) `TARGET_COL` once you know your target column name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/dataset.csv\"   # <- change if your file name differs\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321308f",
   "metadata": {},
   "source": [
    "## 3) Initial exploration\n",
    "\n",
    "We check:\n",
    "- column types\n",
    "- missing values\n",
    "- duplicates\n",
    "- basic stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05bc4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending=False).head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924952bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = df.duplicated().sum()\n",
    "dup_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a12d32",
   "metadata": {},
   "source": [
    "## 4) Data cleaning\n",
    "\n",
    "**Recommended minimum:**\n",
    "- remove duplicates\n",
    "- handle missing values (drop or impute)\n",
    "- sanity-check values (e.g., negative ages, impossible ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "print(\"After duplicates removal:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1118f666",
   "metadata": {},
   "source": [
    "### Missing values strategy\n",
    "\n",
    "Pick **one** approach:\n",
    "- If dataset is large and missingness is small → drop rows with missing target / key columns\n",
    "- Otherwise → impute numeric with median and categorical with most-frequent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd064c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: drop rows where target is missing (update TARGET_COL after you set it)\n",
    "TARGET_COL = None  # <- set like: \"churn\" or \"price\"\n",
    "\n",
    "# If you know the target, uncomment:\n",
    "# df = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "# Quick overall view\n",
    "df.isna().mean().sort_values(ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27fd9f",
   "metadata": {},
   "source": [
    "## 5) Feature overview (categorical vs numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "\n",
    "print(\"Numeric cols:\", len(numeric_cols))\n",
    "print(\"Categorical cols:\", len(categorical_cols))\n",
    "\n",
    "numeric_cols[:10], categorical_cols[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbee5d",
   "metadata": {},
   "source": [
    "## 6) EDA — univariate plots\n",
    "\n",
    "### 6.1 Numeric distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot up to first 6 numeric columns (adjust as needed)\n",
    "cols_to_plot = numeric_cols[:6]\n",
    "\n",
    "for col in cols_to_plot:\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.histplot(df[col].dropna(), kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040eef7",
   "metadata": {},
   "source": [
    "### 6.2 Categorical counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb197da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot up to first 6 categorical columns (adjust as needed)\n",
    "cat_to_plot = categorical_cols[:6]\n",
    "\n",
    "for col in cat_to_plot:\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    top_vals = df[col].astype(str).value_counts().head(15)\n",
    "    sns.barplot(x=top_vals.values, y=top_vals.index)\n",
    "    plt.title(f\"Top categories in {col}\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a2498",
   "metadata": {},
   "source": [
    "## 7) EDA — relationships\n",
    "\n",
    "### 7.1 Correlation heatmap (numeric only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(numeric_cols) > 1:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    corr = df[numeric_cols].corr(numeric_only=True)\n",
    "    sns.heatmap(corr, annot=False)\n",
    "    plt.title(\"Correlation heatmap (numeric features)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e173d00",
   "metadata": {},
   "source": [
    "### 7.2 Target vs feature plots\n",
    "\n",
    "Once you set `TARGET_COL`, you can compare:\n",
    "- numeric feature vs target (boxplot for classification, scatter for regression)\n",
    "- categorical feature vs target (count/mean plots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your target column name here\n",
    "# TARGET_COL = \"your_target\"\n",
    "\n",
    "if TARGET_COL is not None and TARGET_COL in df.columns:\n",
    "    if df[TARGET_COL].dtype in [\"object\", \"category\", \"bool\"]:\n",
    "        # Classification-like target\n",
    "        for col in numeric_cols[:4]:\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            sns.boxplot(x=df[TARGET_COL].astype(str), y=df[col])\n",
    "            plt.title(f\"{col} by {TARGET_COL}\")\n",
    "            plt.xlabel(TARGET_COL)\n",
    "            plt.ylabel(col)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        # Regression-like target\n",
    "        for col in numeric_cols[:4]:\n",
    "            if col == TARGET_COL:\n",
    "                continue\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            sns.scatterplot(x=df[col], y=df[TARGET_COL])\n",
    "            plt.title(f\"{TARGET_COL} vs {col}\")\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel(TARGET_COL)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"Set TARGET_COL to enable target-based plots.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0f014",
   "metadata": {},
   "source": [
    "## 8) Outlier analysis (numeric)\n",
    "\n",
    "We use IQR rule to flag potential outliers for a few numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e943924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outlier_fraction(series: pd.Series) -> float:\n",
    "    s = series.dropna()\n",
    "    if s.empty:\n",
    "        return 0.0\n",
    "    q1, q3 = np.percentile(s, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return ((s < lower) | (s > upper)).mean()\n",
    "\n",
    "outlier_report = []\n",
    "for col in numeric_cols[:10]:\n",
    "    frac = iqr_outlier_fraction(df[col])\n",
    "    outlier_report.append((col, frac))\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_report, columns=[\"column\", \"outlier_fraction\"]).sort_values(\"outlier_fraction\", ascending=False)\n",
    "outlier_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace449d9",
   "metadata": {},
   "source": [
    "## 9) Feature engineering (examples)\n",
    "\n",
    "Add transformations that make sense for your dataset, such as:\n",
    "- ratios (e.g., spend / visits)\n",
    "- logs (for skewed variables)\n",
    "- binning (e.g., age group)\n",
    "- date feature extraction (year/month/day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3eb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: log transform a skewed numeric column (replace with your own)\n",
    "# if \"income\" in df.columns:\n",
    "#     df[\"log_income\"] = np.log1p(df[\"income\"])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193c2a8",
   "metadata": {},
   "source": [
    "## 10) Baseline model\n",
    "\n",
    "Pick the correct baseline depending on your task:\n",
    "\n",
    "### Classification\n",
    "- Logistic Regression\n",
    "- Metric: Accuracy (balanced) or F1 (imbalanced)\n",
    "\n",
    "### Regression\n",
    "- Linear Regression\n",
    "- Metric: RMSE / MAE, plus R²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide task type automatically (best-effort)\n",
    "# If TARGET_COL is numeric -> regression; else -> classification\n",
    "if TARGET_COL is None:\n",
    "    raise ValueError(\"Please set TARGET_COL before modeling.\")\n",
    "\n",
    "y = df[TARGET_COL]\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "# Identify columns\n",
    "numeric_features = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "\n",
    "# Preprocess\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose model\n",
    "is_regression = pd.api.types.is_numeric_dtype(y)\n",
    "\n",
    "if is_regression:\n",
    "    model = LinearRegression()\n",
    "else:\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "if is_regression:\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    print(\"Baseline Regression Results\")\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R2:\", r2)\n",
    "else:\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(\"Baseline Classification Results\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, pred))\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48b1c6",
   "metadata": {},
   "source": [
    "## 11) Metric rationale (write in your own words)\n",
    "\n",
    "Replace the text below with your real explanation.\n",
    "\n",
    "- If you used **Accuracy**: explain class balance + why accuracy makes sense.\n",
    "- If you used **F1**: explain class imbalance + importance of precision/recall tradeoff.\n",
    "- If you used **RMSE/MAE**: explain error units + why you chose it.\n",
    "- Always include 2–6 sentences of interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae28e1c",
   "metadata": {},
   "source": [
    "**Example text (edit):**\n",
    "\n",
    "I chose **Accuracy** as the baseline metric because the target classes are relatively balanced, and accuracy provides a clear overall measure of correct predictions. The baseline model achieves an accuracy of XX on the test set, which sets an initial benchmark. In the next module, I will compare additional models and use cross-validation to confirm stability and improve performance.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
