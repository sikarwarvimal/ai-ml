{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32e8d21",
   "metadata": {},
   "source": [
    "# Exercise Form Classification — Initial Report & Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook:\n",
    "- Loads the exercise image dataset from a folder structure\n",
    "- Builds a metadata DataFrame (exercise, label, size, augmentation flag, etc.)\n",
    "- Performs EDA + visualizations\n",
    "- Adds a **baseline model** using metadata-only features (not image pixels)\n",
    "\n",
    "**Expected dataset structure**\n",
    "```\n",
    "exercise_training_dataset/\n",
    "  squat/\n",
    "    correct/*.jpg\n",
    "    incorrect/*.jpg\n",
    "  pushup/\n",
    "    correct/*.jpg\n",
    "    incorrect/*.jpg\n",
    "  plank/\n",
    "    correct/*.jpg\n",
    "    incorrect/*.jpg\n",
    "  lunge/\n",
    "    correct/*.jpg\n",
    "    incorrect/*.jpg\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f392179",
   "metadata": {},
   "source": [
    "## 2) Load dataset → build metadata DataFrame\n",
    "\n",
    "This cell scans the dataset folders and constructs a DataFrame with one row per image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path (update this if your folder name/path is different)\n",
    "DATASET_PATH = Path(\"exercise_training_dataset\")\n",
    "\n",
    "# Initialize list to store image metadata\n",
    "image_data = []\n",
    "\n",
    "# Define exercise types and labels\n",
    "exercises = [\"squat\", \"pushup\", \"plank\", \"lunge\"]\n",
    "labels = [\"correct\", \"incorrect\"]\n",
    "\n",
    "# Load image paths and metadata\n",
    "for exercise in exercises:\n",
    "    for label in labels:\n",
    "        folder_path = DATASET_PATH / exercise / label\n",
    "        \n",
    "        if folder_path.exists():\n",
    "            # Get all image files (support jpg/jpeg/png)\n",
    "            image_files = []\n",
    "            image_files += list(folder_path.glob(\"*.jpg\"))\n",
    "            image_files += list(folder_path.glob(\"*.jpeg\"))\n",
    "            image_files += list(folder_path.glob(\"*.png\"))\n",
    "            \n",
    "            for img_path in image_files:\n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        width, height = img.size\n",
    "                    \n",
    "                    file_size_kb = img_path.stat().st_size / 1024  # KB\n",
    "                    \n",
    "                    image_data.append({\n",
    "                        \"image_path\": str(img_path),\n",
    "                        \"filename\": img_path.name,\n",
    "                        \"exercise\": exercise,\n",
    "                        \"label\": label,\n",
    "                        \"width\": width,\n",
    "                        \"height\": height,\n",
    "                        \"file_size_kb\": file_size_kb,\n",
    "                        \"is_augmented\": (\"aug\" in img_path.name.lower())\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(image_data)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET LOADED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Dataset path: {DATASET_PATH.resolve()}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f85cb8",
   "metadata": {},
   "source": [
    "## 3) Quick checks (types, missing values, duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc46861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb722d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = df.duplicated().sum()\n",
    "print(\"Duplicate rows:\", dup_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906cea2",
   "metadata": {},
   "source": [
    "## 4) Basic EDA — class balance and exercise distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x=\"label\")\n",
    "plt.title(\"Label distribution (Correct vs Incorrect)\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.countplot(data=df, x=\"exercise\", order=df[\"exercise\"].value_counts().index)\n",
    "plt.title(\"Exercise distribution\")\n",
    "plt.xlabel(\"Exercise\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df, x=\"exercise\", hue=\"label\")\n",
    "plt.title(\"Exercise vs Label\")\n",
    "plt.xlabel(\"Exercise\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e057c",
   "metadata": {},
   "source": [
    "## 5) Image size & file size analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"aspect_ratio\"] = df[\"width\"] / df[\"height\"]\n",
    "df[\"megapixels\"] = (df[\"width\"] * df[\"height\"]) / 1e6\n",
    "\n",
    "df[[\"width\",\"height\",\"aspect_ratio\",\"file_size_kb\",\"megapixels\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"width\", \"height\", \"file_size_kb\", \"aspect_ratio\", \"megapixels\"]:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99037552",
   "metadata": {},
   "source": [
    "## 6) Augmentation check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4850fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x=\"is_augmented\")\n",
    "plt.title(\"Augmented vs Original images\")\n",
    "plt.xlabel(\"Is augmented\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df, x=\"exercise\", hue=\"is_augmented\")\n",
    "plt.title(\"Augmentation by exercise\")\n",
    "plt.xlabel(\"Exercise\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"Augmented\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ba775",
   "metadata": {},
   "source": [
    "## 7) Correlation heatmap (metadata-only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"width\", \"height\", \"file_size_kb\", \"aspect_ratio\", \"megapixels\"]\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(df[num_cols].corr(), annot=True)\n",
    "plt.title(\"Correlation heatmap (metadata features)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe0c0c",
   "metadata": {},
   "source": [
    "## 8) Baseline model (metadata-only)\n",
    "\n",
    "This is a **baseline** using only metadata (sizes, file size, exercise type, augmentation flag).\n",
    "It will not be as strong as a CNN on pixels, but it satisfies the baseline-model requirement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety check\n",
    "required_cols = {\"label\",\"exercise\",\"width\",\"height\",\"file_size_kb\",\"aspect_ratio\",\"megapixels\",\"is_augmented\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in df: {missing}\")\n",
    "\n",
    "# Target: correct(1) vs incorrect(0)\n",
    "y = (df[\"label\"] == \"correct\").astype(int)\n",
    "\n",
    "X = df[[\"exercise\", \"width\", \"height\", \"file_size_kb\", \"aspect_ratio\", \"megapixels\", \"is_augmented\"]]\n",
    "\n",
    "categorical_features = [\"exercise\", \"is_augmented\"]\n",
    "numeric_features = [\"width\", \"height\", \"file_size_kb\", \"aspect_ratio\", \"megapixels\"]\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(\"Baseline Accuracy:\", acc)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, pred))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255878c",
   "metadata": {},
   "source": [
    "## 9) Results summary\n",
    "\n",
    "Run the cells below after loading the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key dataset summary numbers\n",
    "print(\"=== DATASET SUMMARY ===\")\n",
    "print(\"Total images:\", len(df))\n",
    "print(\"\\nImages per exercise:\\n\", df[\"exercise\"].value_counts())\n",
    "print(\"\\nImages per label:\\n\", df[\"label\"].value_counts())\n",
    "print(\"\\nImages per (exercise, label):\\n\", pd.crosstab(df[\"exercise\"], df[\"label\"]))\n",
    "\n",
    "# Class balance\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "total = label_counts.sum()\n",
    "print(\"\\nClass balance (%):\")\n",
    "for k, v in label_counts.items():\n",
    "    print(f\"  {k}: {100*v/total:.2f}%\")\n",
    "\n",
    "# Augmentation\n",
    "print(\"\\nAugmented images:\", df[\"is_augmented\"].sum())\n",
    "print(\"Original images:\", (~df[\"is_augmented\"]).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaeafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning results (duplicates + missing)\n",
    "print(\"=== CLEANING CHECKS ===\")\n",
    "print(\"Missing values per column (non-zero only):\")\n",
    "missing = df.isna().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(missing if len(missing) else \"No missing values found in df metadata.\")\n",
    "\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf99a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier fractions using IQR rule (metadata numeric columns)\n",
    "def iqr_outlier_fraction(series: pd.Series) -> float:\n",
    "    s = series.dropna()\n",
    "    if s.empty:\n",
    "        return 0.0\n",
    "    q1, q3 = np.percentile(s, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return ((s < lower) | (s > upper)).mean()\n",
    "\n",
    "num_cols = [\"width\", \"height\", \"file_size_kb\", \"aspect_ratio\", \"megapixels\"]\n",
    "outlier_report = {col: iqr_outlier_fraction(df[col]) for col in num_cols}\n",
    "\n",
    "print(\"=== OUTLIER REPORT (IQR FRACTION) ===\")\n",
    "for col, frac in sorted(outlier_report.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{col}: {frac:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb9e13c",
   "metadata": {},
   "source": [
    "## 10) Baseline model result \n",
    "\n",
    "Below cell prints the baseline metric again in a compact way for your report text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== BASELINE MODEL RESULT ===\")\n",
    "print(\"Metric: Accuracy (classification baseline)\")\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1f5c6",
   "metadata": {},
   "source": [
    "## 11) Executive brief \n",
    "\n",
    "\n",
    "Edit the bracketed parts after you run the notebook. Keep it short and clear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66017ca6",
   "metadata": {},
   "source": [
    "**Executive brief (edit after running):**\n",
    "\n",
    "- **Goal:** Classify exercise form as **correct vs incorrect** across four exercises (squat, pushup, plank, lunge).\n",
    "- **Dataset:** `exercise_training_dataset/` with a total of **[TOTAL_IMAGES]** images (including **[AUG_COUNT]** augmented images).\n",
    "- **Data quality checks:** Missing values in metadata: **[NONE / LIST]**. Duplicate metadata rows: **[DUP_COUNT]**.\n",
    "- **EDA insights:** Class balance is **[BALANCED / IMBALANCED]** with correct = **[X%]** and incorrect = **[Y%]**. Image sizes vary (see width/height distributions) and file size correlates with resolution (see correlation heatmap).\n",
    "- **Outliers:** Potential anomalies exist primarily in **[COLUMN_NAMES]** (IQR outlier fractions reported above).\n",
    "- **Baseline model:** A **Logistic Regression** baseline using **metadata-only** features achieved **Accuracy = [ACC]** on the test split, providing a benchmark for more advanced image-based models in the next module.\n",
    "- **Next steps:** Train an image-based CNN (or transfer learning), improve preprocessing/augmentation, and compare multiple models using cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05976120",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
